"""
ManagementAPIClient - HTTP client for CLIProxyAPI Management API.

WORKFLOW OVERVIEW:
==================
This module provides the HTTP client for communicating with the CLIProxyAPI
management API. The proxy exposes a REST API for managing auth files, quotas,
OAuth flows, and other operations.

KEY RESPONSIBILITIES:
1. HTTP Communication:
   - Makes authenticated requests to proxy management API
   - Handles timeouts and retries
   - Manages connection pooling and resource limits

2. API Operations:
   - Fetch auth files (list of connected accounts)
   - Manage OAuth flows (get URL, poll status)
   - Fetch quotas from providers
   - Manage API keys
   - Fetch usage statistics

3. Error Handling:
   - Retries failed requests
   - Handles network errors gracefully
   - Provides detailed error messages

ARCHITECTURE:
Uses aiohttp for async HTTP requests. The session is configured with:
- Connection pooling (limits to prevent resource exhaustion)
- Timeouts (different for local vs remote connections)
- Retry logic (configurable per connection type)
"""

import asyncio
import json
from typing import Optional, List, Dict
from dataclasses import dataclass

import aiohttp

from ..models.auth import (
    AuthFile,
    AuthFilesResponse,
    OAuthURLResponse,
    OAuthStatusResponse,
)
from ..models.providers import AIProvider


@dataclass
class TimeoutConfig:
    """
    Timeout configuration for API requests.

    Different timeout values for local vs remote connections:
    - Local: Faster timeouts (proxy is on same machine)
    - Remote: Longer timeouts (network latency, potential delays)
    """
    request_timeout: float = 15.0  # Timeout for individual requests
    resource_timeout: float = 45.0  # Total timeout for entire operation
    max_retries: int = 1  # Number of retry attempts

    @classmethod
    def local(cls):
        """Default timeouts for local connections (faster)."""
        return cls(request_timeout=15.0, resource_timeout=45.0, max_retries=1)

    @classmethod
    def remote(cls):
        """Timeouts for remote connections (longer, accounts for network latency)."""
        return cls(request_timeout=30.0, resource_timeout=90.0, max_retries=2)


class APIError(Exception):
    """API-related errors."""
    pass


class ManagementAPIClient:
    """
    HTTP client for CLIProxyAPI Management API.

    WORKFLOW:
    This client handles all HTTP communication with the proxy's management API.
    It provides methods for:
    - Fetching auth files (list of connected accounts)
    - Managing OAuth flows (getting URLs, polling status)
    - Fetching quotas and usage statistics
    - Managing API keys

    CONNECTION MANAGEMENT:
    Uses aiohttp with connection pooling to efficiently manage HTTP connections.
    Limits are set to prevent resource exhaustion (max 10 connections, 5 per host).

    AUTHENTICATION:
    All requests include an Authorization header with the management key.
    This key is generated by the proxy manager and stored securely.
    """

    def __init__(
        self,
        base_url: str,
        auth_key: str,
        timeout_config: Optional[TimeoutConfig] = None,
    ):
        """
        Initialize the API client.

        Args:
            base_url: Base URL of the proxy management API (e.g., "http://127.0.0.1:8317/v0/management")
            auth_key: Management key for API authentication
            timeout_config: Timeout configuration (defaults to local timeouts)
        """
        self.base_url = base_url.rstrip("/")
        self.auth_key = auth_key
        self.timeout_config = timeout_config or TimeoutConfig.local()
        # Detect if this is a remote connection (not localhost)
        self.is_remote = not base_url.startswith("http://127.0.0.1") and not base_url.startswith("http://localhost")

        # Create session with timeout and connector limits
        # Timeouts prevent hanging requests
        timeout = aiohttp.ClientTimeout(
            total=self.timeout_config.resource_timeout,  # Total time for entire operation
            connect=self.timeout_config.request_timeout,  # Time to establish connection
        )
        # Limit connections to prevent resource exhaustion
        # Connection pooling allows reuse of TCP connections for better performance
        connector = aiohttp.TCPConnector(
            limit=10,  # Max 10 total connections in pool
            limit_per_host=5,  # Max 5 connections per host
            ttl_dns_cache=300,  # DNS cache TTL (5 minutes)
            force_close=True,  # Force close connections after use (prevents connection reuse issues)
        )
        self.session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
        )

    async def close(self):
        """Close the session and connector."""
        try:
            # Close the session (this will close all connections)
            await self.session.close()
            # Close the connector explicitly to ensure all connections are closed
            if hasattr(self.session, 'connector') and self.session.connector:
                await self.session.connector.close()
        except Exception as e:
            # Ignore errors during close - session might already be closed
            print(f"[APIClient] Error during close: {e}")

    async def __aenter__(self):
        """Async context manager entry."""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        await self.close()

    async def _make_request(
        self,
        endpoint: str,
        method: str = "GET",
        body: Optional[bytes] = None,
        retry_count: int = 0,
    ) -> bytes:
        """Make an HTTP request with retry logic."""
        url = f"{self.base_url}{endpoint}"

        headers = {
            "Authorization": f"Bearer {self.auth_key}",
            "Content-Type": "application/json",
            "Connection": "close",  # Force new connection
        }

        try:
            # Check if session is closed
            if self.session.closed:
                raise APIError("Session is closed")

            # Use a timeout to prevent hanging
            timeout = aiohttp.ClientTimeout(
                total=self.timeout_config.resource_timeout,
                connect=self.timeout_config.request_timeout,
            )

            async with self.session.request(
                method=method,
                url=url,
                headers=headers,
                data=body,
                timeout=timeout,
            ) as response:
                if response.status not in range(200, 300):
                    error_text = await response.text()
                    raise APIError(f"HTTP {response.status}: {error_text}")

                # Read response data
                data = await response.read()
                return data
        except (aiohttp.ClientError, asyncio.TimeoutError, ConnectionError) as e:
            # Retry on connection errors
            if retry_count < self.timeout_config.max_retries:
                await asyncio.sleep(0.5)
                return await self._make_request(endpoint, method, body, retry_count + 1)
            # Get detailed error message
            error_msg = str(e) if e else "Unknown connection error"
            error_type = type(e).__name__
            if not error_msg or error_msg == "Unknown connection error":
                # Try to get more details from the exception
                if hasattr(e, 'message'):
                    error_msg = str(e.message)
                elif hasattr(e, 'args') and e.args:
                    error_msg = str(e.args[0]) if e.args[0] else error_type
                else:
                    error_msg = error_type
            raise APIError(f"Connection error ({error_type}): {error_msg}")
        except Exception as e:
            # Catch any other exceptions to prevent crashes
            error_msg = str(e) if e else "Unknown error"
            raise APIError(f"Request error: {error_msg}")

    async def check_proxy_responding(self) -> bool:
        """Check if proxy is responding."""
        try:
            await self._make_request("/auth-files")
            return True
        except Exception:
            return False

    async def fetch_auth_files(self) -> list[AuthFile]:
        """Fetch all auth files."""
        data = await self._make_request("/auth-files")
        import json
        response_data = json.loads(data.decode("utf-8"))
        # Convert dict to AuthFile objects
        files = [AuthFile(**item) for item in response_data.get("files", [])]
        return files

    async def delete_auth_file(self, name: str):
        """Delete an auth file."""
        # Security: Proper URL encoding
        from urllib.parse import quote
        encoded_name = quote(name, safe='')
        await self._make_request(f"/auth-files?name={encoded_name}", method="DELETE")

    async def get_oauth_url(
        self,
        provider: AIProvider,
        project_id: Optional[str] = None,
    ) -> OAuthURLResponse:
        """Get OAuth URL for a provider."""
        endpoint = provider.oauth_endpoint
        if not endpoint:
            raise APIError(f"Provider {provider} does not support OAuth")

        query_params = []
        if project_id and provider == AIProvider.GEMINI:
            query_params.append(f"project_id={project_id}")

        # Add web UI flag for supported providers
        web_ui_providers = {
            AIProvider.ANTIGRAVITY,
            AIProvider.CLAUDE,
            AIProvider.CODEX,
            AIProvider.GEMINI,
            AIProvider.IFLOW,
            AIProvider.KIRO,
        }
        if provider in web_ui_providers:
            query_params.append("is_webui=true")

        if query_params:
            endpoint += "?" + "&".join(query_params)

        # base_url already includes /v0/management, so just use the endpoint
        data = await self._make_request(endpoint)
        import json
        return OAuthURLResponse(**json.loads(data.decode("utf-8")))

    async def poll_oauth_status(self, state: str) -> OAuthStatusResponse:
        """Poll OAuth status."""
        data = await self._make_request(f"/get-auth-status?state={state}")
        import json
        return OAuthStatusResponse(**json.loads(data.decode("utf-8")))

    async def fetch_api_keys(self) -> list[str]:
        """Fetch all API keys from the proxy."""
        print(f"[ManagementAPIClient] fetch_api_keys: base_url={self.base_url}, is_remote={self.is_remote}")
        try:
            data = await self._make_request("/api-keys")
            response = data.decode("utf-8")
            # Parse JSON array
            import json
            keys = json.loads(response).get("api-keys", [])
            print(f"[ManagementAPIClient] fetch_api_keys: Successfully fetched {len(keys)} API key(s)")
            return keys
        except Exception as e:
            print(f"[ManagementAPIClient] fetch_api_keys: Error - {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            raise

    async def add_api_key(self, key: str):
        """Add an API key."""
        current_keys = await self.fetch_api_keys()
        current_keys.append(key)
        await self.replace_api_keys(current_keys)

    async def replace_api_keys(self, keys: list[str]):
        """Replace all API keys."""
        import json
        body = json.dumps(keys).encode("utf-8")
        await self._make_request("/api-keys", method="PUT", body=body)

    async def delete_api_key(self, value: str):
        """Delete an API key."""
        # Security: Proper URL encoding
        from urllib.parse import quote
        encoded_value = quote(value, safe='')
        await self._make_request(f"/api-keys?value={encoded_value}", method="DELETE")

    async def upload_vertex_service_account(self, data: bytes):
        """Upload Vertex AI service account JSON."""
        headers = {
            "Authorization": f"Bearer {self.auth_key}",
            "Content-Type": "application/json",
        }
        # base_url already includes /v0/management
        url = f"{self.base_url}/vertex/import"
        async with self.session.post(url, headers=headers, data=data) as response:
            if response.status not in range(200, 300):
                raise APIError(f"Upload failed: {response.status}")

    async def fetch_usage_stats(self, timeout: Optional[float] = None):
        """Fetch usage statistics.

        Args:
            timeout: Optional timeout override (in seconds). If None, uses default timeout_config.
        """
        from ..models.usage_stats import UsageStats

        # Use shorter timeout for usage stats (frequent polling operation)
        # Default to 8 seconds for usage stats to fail fast and retry quickly
        if timeout is None:
            timeout = 8.0

        # Create a timeout wrapper for this specific request
        try:
            data = await asyncio.wait_for(
                self._make_request("/usage"),
                timeout=timeout
            )
            import json
            return UsageStats.from_dict(json.loads(data.decode("utf-8")))
        except asyncio.TimeoutError:
            # Re-raise with more context
            raise APIError(f"Usage stats request timed out after {timeout}s")

    # MARK: - Advanced Proxy Configuration Methods

    async def fetch_config(self) -> dict:
        """Fetch the full configuration from the proxy."""
        data = await self._make_request("/config")
        import json
        return json.loads(data.decode())

    async def get_proxy_url(self) -> str:
        """Get upstream proxy URL."""
        data = await self._make_request("/proxy-url")
        import json
        response = json.loads(data.decode())
        return response.get("proxy-url", response.get("proxyURL", ""))

    async def set_proxy_url(self, url: str) -> None:
        """Set upstream proxy URL."""
        import json
        body = json.dumps({"value": url}).encode()
        await self._make_request("/proxy-url", method="PUT", body=body)

    async def delete_proxy_url(self) -> None:
        """Delete/clear upstream proxy URL."""
        await self._make_request("/proxy-url", method="DELETE")

    async def get_routing_strategy(self) -> str:
        """Get routing strategy."""
        try:
            # Try new endpoint first
            data = await self._make_request("/routing/strategy")
            import json
            response = json.loads(data.decode())
            return response.get("strategy", "round-robin")
        except Exception:
            # Fall back to legacy endpoint
            data = await self._make_request("/routing")
            import json
            response = json.loads(data.decode())
            return response.get("strategy", "round-robin")

    async def set_routing_strategy(self, strategy: str) -> None:
        """Set routing strategy."""
        import json
        body = json.dumps({"value": strategy}).encode()
        try:
            # Try new endpoint first
            await self._make_request("/routing/strategy", method="PUT", body=body)
        except Exception:
            # Fall back to legacy endpoint
            legacy_body = json.dumps({"strategy": strategy}).encode()
            await self._make_request("/routing", method="PUT", body=legacy_body)

    async def get_quota_exceeded_switch_project(self) -> bool:
        """Get quota exceeded switch project setting."""
        data = await self._make_request("/quota-exceeded/switch-project")
        import json
        response = json.loads(data.decode())
        return response.get("value", True)

    async def set_quota_exceeded_switch_project(self, enabled: bool) -> None:
        """Set quota exceeded switch project setting."""
        import json
        body = json.dumps({"value": enabled}).encode()
        await self._make_request("/quota-exceeded/switch-project", method="PATCH", body=body)

    async def get_quota_exceeded_switch_preview_model(self) -> bool:
        """Get quota exceeded switch preview model setting."""
        data = await self._make_request("/quota-exceeded/switch-preview-model")
        import json
        response = json.loads(data.decode())
        return response.get("value", True)

    async def set_quota_exceeded_switch_preview_model(self, enabled: bool) -> None:
        """Set quota exceeded switch preview model setting."""
        import json
        body = json.dumps({"value": enabled}).encode()
        await self._make_request("/quota-exceeded/switch-preview-model", method="PATCH", body=body)

    async def get_request_retry(self) -> int:
        """Get request retry count."""
        data = await self._make_request("/request-retry")
        import json
        response = json.loads(data.decode())
        return response.get("request-retry", response.get("requestRetry", 3))

    async def set_request_retry(self, count: int) -> None:
        """Set request retry count."""
        import json
        body = json.dumps({"value": count}).encode()
        await self._make_request("/request-retry", method="PUT", body=body)

    async def get_max_retry_interval(self) -> int:
        """Get max retry interval in seconds."""
        data = await self._make_request("/max-retry-interval")
        import json
        response = json.loads(data.decode())
        return response.get("max-retry-interval", response.get("maxRetryInterval", 30))

    async def set_max_retry_interval(self, seconds: int) -> None:
        """Set max retry interval in seconds."""
        import json
        body = json.dumps({"value": seconds}).encode()
        await self._make_request("/max-retry-interval", method="PUT", body=body)

    async def get_logging_to_file(self) -> bool:
        """Get logging to file status."""
        data = await self._make_request("/logging-to-file")
        import json
        response = json.loads(data.decode())
        return response.get("logging-to-file", response.get("loggingToFile", True))

    async def set_logging_to_file(self, enabled: bool) -> None:
        """Set logging to file."""
        import json
        body = json.dumps({"value": enabled}).encode()
        await self._make_request("/logging-to-file", method="PUT", body=body)

    async def get_request_log(self) -> bool:
        """Get request log status."""
        data = await self._make_request("/request-log")
        import json
        response = json.loads(data.decode())
        return response.get("request-log", response.get("requestLog", False))

    async def set_request_log(self, enabled: bool) -> None:
        """Set request log."""
        import json
        body = json.dumps({"value": enabled}).encode()
        await self._make_request("/request-log", method="PUT", body=body)

    async def get_debug(self) -> bool:
        """Get debug mode status."""
        data = await self._make_request("/debug")
        import json
        response = json.loads(data.decode())
        return response.get("debug", False)

    async def set_debug(self, enabled: bool) -> None:
        """Set debug mode."""
        import json
        body = json.dumps({"value": enabled}).encode()
        await self._make_request("/debug", method="PUT", body=body)

    async def fetch_auth_file_models(self, name: str) -> List[dict]:
        """Fetch available models for an auth file.

        Args:
            name: Auth file name

        Returns:
            List of model info dictionaries with 'id', 'owned_by', 'type' keys
        """
        from urllib.parse import quote
        encoded_name = quote(name)
        data = await self._make_request(f"/auth-files/models?name={encoded_name}")
        response = json.loads(data.decode())
        return response.get("models", [])

    async def api_call(
        self,
        auth_index: Optional[str],
        method: str,
        url: str,
        headers: Optional[Dict[str, str]] = None,
        data: Optional[str] = None
    ) -> dict:
        """Make a generic API call through the proxy.

        Args:
            auth_index: Auth file index (optional)
            method: HTTP method (GET, POST, etc.)
            url: Full URL to call
            headers: Optional headers dict
            data: Optional request body as string

        Returns:
            Response dict with 'status_code' and 'body' keys
        """
        payload = {
            "method": method,
            "url": url,
        }
        if auth_index:
            payload["auth_index"] = auth_index
        if headers:
            payload["header"] = headers
        if data:
            payload["data"] = data

        body = json.dumps(payload).encode()
        response_data = await self._make_request("/api-call", method="POST", body=body)
        return json.loads(response_data.decode())
